{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL OF THIS IS IRRELEVANT FOR NIR; JUST USING THIS TO FIGURE OUT HOW TO SAVE THESE VALUES\n",
    "\n",
    "DECODER_DIMS = {\"text\": 0, \"bin\": 0, \"cat\": 0, \"bp\": 0, \"indus\": 0}\n",
    "ENCODER_DIMS = 0\n",
    "K = 0\n",
    "\n",
    "FOLDS = 4\n",
    "BATCHES = 0\n",
    "ITERS = 0\n",
    "\n",
    "ADAM_LR = 0\n",
    "MIN_AF = 0\n",
    "ANNEALING_BATCHES = 0\n",
    "NUM_PARTICLES = 0\n",
    "\n",
    "CENTER_BP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro import poutine\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import combinations\n",
    "\n",
    "from metrics import Metrics\n",
    "from data import SplitData\n",
    "\n",
    "\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "smoke_test = 'CI' in os.environ\n",
    "\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "def compute_distance(z):\n",
    "    b = z.reshape(z.shape[0], 1, z.shape[1])\n",
    "    return np.sqrt(np.einsum('ijk, ijk->ij', z-b, z-b))\n",
    "\n",
    "def convert_onehot_K(intvec, K):\n",
    "    N = len(intvec)\n",
    "    return np.array([np.array([1 if i==intvec[j] else 0 for i in range(K)]) for j in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "First, load text data, and apply word filter. Note on notation: `tx` stands for \"true x,\" because the model variables are also called x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf = pd.read_csv(\"../../../data/web_dtfm20_binary.csv\", index_col=0)\n",
    "tx_text = textdf.values\n",
    "seltext = tx_text.sum(0) > 0.05\n",
    "tx_text = textdf.values[:,seltext]\n",
    "\n",
    "gt20words = tx_text.sum(1) > 20\n",
    "tx_text = tx_text[gt20words,:]\n",
    "\n",
    "words = textdf.columns[seltext]\n",
    "N, V = tx_text.shape\n",
    "\n",
    "binfeats = pd.read_csv(\"../../../data/y_bin_all_py2.csv\", index_col=0)\n",
    "tx_b = binfeats.values\n",
    "tx_b = tx_b[gt20words,:]\n",
    "M_b = tx_b.shape[1]\n",
    "\n",
    "catfeats = pd.read_csv(\"../../../data/y_mult_ncolors_py2.csv\", index_col=0)\n",
    "\n",
    "tx_c1 = catfeats.values[:,0][gt20words]\n",
    "M_c1 = len(np.unique(tx_c1))\n",
    "tx_c1 = np.expand_dims(tx_c1, 1)\n",
    "\n",
    "tx_c2 = catfeats.values[:,1][gt20words]\n",
    "M_c2 = len(np.unique(tx_c2))\n",
    "tx_c2 = np.expand_dims(tx_c2, 1)\n",
    "\n",
    "tx_c3 = catfeats.values[:,2][gt20words]\n",
    "M_c3 = len(np.unique(tx_c3))\n",
    "tx_c3 = np.expand_dims(tx_c3, 1)\n",
    "\n",
    "tx_c4 = catfeats.values[:,3][gt20words]\n",
    "M_c4 = len(np.unique(tx_c4))\n",
    "tx_c4 = np.expand_dims(tx_c4, 1)\n",
    "\n",
    "tx_c5 = catfeats.values[:,4][gt20words]\n",
    "M_c5 = len(np.unique(tx_c5))\n",
    "tx_c5 = np.expand_dims(tx_c5, 1)\n",
    "\n",
    "c1_labels = np.array([\"black\",\"blue_dark\",\"blue_light\",\"blue_medium\",\"brown\",\"green_dark\",\n",
    "                      \"green_light\",\"grey_dark\",\"grey_light\",\"orange\",\"red\",\"red_dark\",\n",
    "                      \"yellow\"])\n",
    "\n",
    "c2_labels = np.array([\"circle\",\"rect-oval_medium\",\"rect-oval_large\",\"rect-oval_thin\",\n",
    "                      \"square\",\"triangle\"])\n",
    "\n",
    "c3_labels = np.array([\"bad_letters\",\"bulky_hollow_geometric\",\"circular\",\"dense_simple_geom\",\n",
    "                      \"detailed_circle\",\"hollow_circle\",\"detailed_hor\",\"long_hor\",\"no_mark\",\n",
    "                      \"simple\",\"square\",\"thin_vert_rect\",\"vert_narrow\",\"detailed\",\"thin\",\n",
    "                      \"hor_wispy\"])\n",
    "\n",
    "c4_labels = np.array([\"nochars\",\"sans\",\"serif\"])\n",
    "\n",
    "c5_labels = np.array([\"one_color\",\"two_colors\",\"three_colors\",\"many_colors\"])\n",
    "\n",
    "bp = pd.read_csv(\"../../../data/bp_avg_all_traits.csv\", index_col=0)\n",
    "\n",
    "tx_bp = bp.values\n",
    "tx_bp = tx_bp[gt20words]\n",
    "if CENTER_BP:\n",
    "    tx_bp = (tx_bp - tx_bp.mean(0)) / tx_bp.std(0)\n",
    "M_bp = tx_bp.shape[1]\n",
    "\n",
    "indus = pd.read_csv(\"../../../data/industry_codes_updated.csv\", index_col=0)\n",
    "indus = indus.iloc[np.in1d(indus.index, bp.index),:]\n",
    "indus = indus.sort_index()\n",
    "\n",
    "tx_indus = indus.values.astype('int')\n",
    "tx_indus = tx_indus[:, tx_indus.sum(0) > 9]\n",
    "tx_indus = tx_indus[gt20words,:]\n",
    "M_indus = tx_indus.shape[1]\n",
    "\n",
    "indus_labels = indus.columns[indus.values.sum(0) > 9]\n",
    "\n",
    "allnames = binfeats.index.values[gt20words]\n",
    "\n",
    "x_sizes = {\"text\": V, \n",
    "           \"bin\": M_b, \n",
    "           \"cat1\": M_c1, \n",
    "           \"cat2\": M_c2, \n",
    "           \"cat3\": M_c3, \n",
    "           \"cat4\": M_c4, \n",
    "           \"cat5\": M_c5, \n",
    "           \"bp\": M_bp, \n",
    "           \"indus\": M_indus, \n",
    "           \"logo\": M_b + 5, \n",
    "           \"all\": V + M_b + 5 + M_bp + M_indus}\n",
    "\n",
    "task_sizes = {\"full\": x_sizes[\"all\"], \n",
    "              \"logo\": x_sizes[\"bin\"] + 5, \n",
    "              \"design\": x_sizes[\"text\"] + x_sizes[\"bp\"] + x_sizes[\"indus\"], \n",
    "              \"mgr\": x_sizes[\"all\"] - x_sizes[\"bp\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Instantiate Model and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "givens = pd.DataFrame(np.concatenate(([[K], list(DECODER_DIMS.values()), [ENCODER_DIMS], [BATCHES], [ITERS], [ADAM_LR], [ANNEALING_BATCHES], [NUM_PARTICLES], [CENTER_BP]]))).T\n",
    "givens.columns = [\"K\", \"text_dec\", \"bin_dec\", \"cat_dec\", \"bp_dec\", \"indus_dec\", \"all_enc\", \"batches\", \"iters\", \"adam_lr\", \"annealing_batches\", \"num_particles\", \"center_bp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create holdout and cross-validation subsets (just the indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FOLDS > 1:\n",
    "    holdout_indices = list(split(np.arange(N), FOLDS))\n",
    "    holdout_indices.append(np.array([]))\n",
    "    fold_indices = [np.setdiff1d(np.arange(N), holdout_indices[i]) for i in range(FOLDS)]\n",
    "    fold_indices.append(np.arange(N))\n",
    "else:\n",
    "    holdout_indices = [np.array([])]\n",
    "    fold_indices = [np.arange(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoInfoPredict():\n",
    "    def __init__(self, data, N, K_vec):\n",
    "        self.text = np.tile(data.x_text.mean(0), (N,1))\n",
    "        self.bin = np.tile(data.x_bin.mean(0), (N,1))\n",
    "        self.cat1 = np.tile(convert_onehot_K(data.x_cat1.flatten(), K_vec[0]).mean(0), (N,1))\n",
    "        self.cat2 = np.tile(convert_onehot_K(data.x_cat2.flatten(), K_vec[1]).mean(0), (N,1))\n",
    "        self.cat3 = np.tile(convert_onehot_K(data.x_cat3.flatten(), K_vec[2]).mean(0), (N,1))\n",
    "        self.cat4 = np.tile(convert_onehot_K(data.x_cat4.flatten(), K_vec[3]).mean(0), (N,1))\n",
    "        self.cat5 = np.tile(convert_onehot_K(data.x_cat5.flatten(), K_vec[4]).mean(0), (N,1))\n",
    "        self.bp = np.tile(data.x_bp.mean(0), (N,1))\n",
    "        self.indus = np.tile(data.x_indus.mean(0), (N,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8d15260ca847d4b89882931b955e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryandew/anaconda3/envs/pyro/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Check if there's already a save file; if so, augment the save index so the metrics are not overwritten:\n",
    "curfiles = os.listdir()\n",
    "existing_indices = []\n",
    "for file in curfiles:\n",
    "    if(len(file.split(\"_\")) > 1):\n",
    "        if(file.split(\"_\")[-1] == 'metrics.csv'):\n",
    "            existing_indices.append(int(file.split(\"_\")[0]))\n",
    "            \n",
    "if len(existing_indices) > 0:\n",
    "    save_index = max(existing_indices) + 1\n",
    "else:\n",
    "    save_index = 0\n",
    "    \n",
    "    \n",
    "K_vec = np.array([M_c1, M_c2, M_c3, M_c4, M_c5])\n",
    "\n",
    "\n",
    "# Run the model across all folds (sequentially):\n",
    "for fold in tqdm(range(FOLDS+1), desc=\"Folds\"):\n",
    "\n",
    "   \n",
    "    data = SplitData(tx_text, tx_b, tx_c1, tx_c2, tx_c3, tx_c4, tx_c5, tx_bp, tx_indus, \n",
    "                     allnames, test_indices = holdout_indices[fold])     \n",
    "\n",
    "    data.training.make_torch()\n",
    "\n",
    "    nipred = NoInfoPredict(data.training, data.training.N, K_vec)\n",
    "    nir_training = Metrics(data.training, nipred, K_vec)\n",
    "    nir_training.summarize(path = str(save_index) + \"_training_metrics.csv\", index = fold, givens = givens)\n",
    "    nir_training.save_features_table(path = str(save_index) + \"_training_bin_features.csv\", names = binfeats.columns, index = fold, givens = givens)\n",
    "\n",
    "    if hasattr(data, 'test'):\n",
    "        data.test.make_torch()\n",
    "\n",
    "        nipred = NoInfoPredict(data.training, data.test.N, K_vec)\n",
    "        nir_test = Metrics(data.test, nipred, K_vec)\n",
    "        nir_test.summarize(path = str(save_index) + \"_test_metrics.csv\", index = fold, givens = givens)\n",
    "        nir_test.save_features_table(path = str(save_index) + \"_test_bin_features.csv\", names = binfeats.columns, index = fold, givens = givens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
