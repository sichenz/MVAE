{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECODER_DIMS = {\"text\": 400, \"bin\": 400, \"cat\": 400, \"bp\": 400, \"indus\": 400}\n",
    "ENCODER_DIMS = 1000\n",
    "K = 40\n",
    "\n",
    "FOLDS = 0\n",
    "BATCHES = 1000\n",
    "ITERS = 100\n",
    "\n",
    "ADAM_LR = 0.0001\n",
    "MIN_AF = 1e-6\n",
    "ANNEALING_BATCHES = 500\n",
    "NUM_PARTICLES = 1\n",
    "\n",
    "CENTER_BP = True\n",
    "\n",
    "DISABLE_TQDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.contrib.examples.util  # patches torchvision\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro import poutine\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from data import SplitData\n",
    "from model import LogoMVAE\n",
    "\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "def compute_distance(z):\n",
    "    b = z.reshape(z.shape[0], 1, z.shape[1])\n",
    "    return np.sqrt(np.einsum('ijk, ijk->ij', z-b, z-b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "First, load text data, and apply word filter. Note on notation: `tx` stands for \"true x,\" because the model variables are also called x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf = pd.read_csv(\"../../../data/web_dtfm20_binary.csv\", index_col=0)\n",
    "tx_text = textdf.values\n",
    "seltext = tx_text.sum(0) > 0.05\n",
    "tx_text = textdf.values[:,seltext]\n",
    "\n",
    "gt20words = tx_text.sum(1) > 20\n",
    "tx_text = tx_text[gt20words,:]\n",
    "\n",
    "words = textdf.columns[seltext]\n",
    "N, V = tx_text.shape\n",
    "\n",
    "binfeats = pd.read_csv(\"../../../data/y_bin_all_py2.csv\", index_col=0)\n",
    "tx_b = binfeats.values\n",
    "tx_b = tx_b[gt20words,:]\n",
    "M_b = tx_b.shape[1]\n",
    "\n",
    "catfeats = pd.read_csv(\"../../../data/y_mult_ncolors_py2.csv\", index_col=0)\n",
    "\n",
    "tx_c1 = catfeats.values[:,0][gt20words]\n",
    "M_c1 = len(np.unique(tx_c1))\n",
    "tx_c1 = np.expand_dims(tx_c1, 1)\n",
    "\n",
    "tx_c2 = catfeats.values[:,1][gt20words]\n",
    "M_c2 = len(np.unique(tx_c2))\n",
    "tx_c2 = np.expand_dims(tx_c2, 1)\n",
    "\n",
    "tx_c3 = catfeats.values[:,2][gt20words]\n",
    "M_c3 = len(np.unique(tx_c3))\n",
    "tx_c3 = np.expand_dims(tx_c3, 1)\n",
    "\n",
    "tx_c4 = catfeats.values[:,3][gt20words]\n",
    "M_c4 = len(np.unique(tx_c4))\n",
    "tx_c4 = np.expand_dims(tx_c4, 1)\n",
    "\n",
    "tx_c5 = catfeats.values[:,4][gt20words]\n",
    "M_c5 = len(np.unique(tx_c5))\n",
    "tx_c5 = np.expand_dims(tx_c5, 1)\n",
    "\n",
    "c1_labels = np.array([\"black\",\"blue_dark\",\"blue_light\",\"blue_medium\",\"brown\",\"green_dark\",\n",
    "                      \"green_light\",\"grey_dark\",\"grey_light\",\"orange\",\"red\",\"red_dark\",\n",
    "                      \"yellow\"])\n",
    "\n",
    "c2_labels = np.array([\"circle\",\"rect-oval_medium\",\"rect-oval_large\",\"rect-oval_thin\",\n",
    "                      \"square\",\"triangle\"])\n",
    "\n",
    "c3_labels = np.array([\"bad_letters\",\"bulky_hollow_geometric\",\"circular\",\"dense_simple_geom\",\n",
    "                      \"detailed_circle\",\"hollow_circle\",\"detailed_hor\",\"long_hor\",\"no_mark\",\n",
    "                      \"simple\",\"square\",\"thin_vert_rect\",\"vert_narrow\",\"detailed\",\"thin\",\n",
    "                      \"hor_wispy\"])\n",
    "\n",
    "c4_labels = np.array([\"nochars\",\"sans\",\"serif\"])\n",
    "\n",
    "c5_labels = np.array([\"one_color\",\"two_colors\",\"three_colors\",\"many_colors\"])\n",
    "\n",
    "bp = pd.read_csv(\"../../../data/bp_avg_all_traits.csv\", index_col=0)\n",
    "\n",
    "tx_bp = bp.values\n",
    "tx_bp = tx_bp[gt20words]\n",
    "if CENTER_BP:\n",
    "    tx_bp = (tx_bp - tx_bp.mean(0)) / tx_bp.std(0)\n",
    "M_bp = tx_bp.shape[1]\n",
    "\n",
    "indus = pd.read_csv(\"../../../data/industry_codes_updated.csv\", index_col=0)\n",
    "indus = indus.iloc[np.in1d(indus.index, bp.index),:]\n",
    "indus = indus.sort_index()\n",
    "\n",
    "tx_indus = indus.values.astype('int')\n",
    "tx_indus = tx_indus[:, tx_indus.sum(0) > 9]\n",
    "tx_indus = tx_indus[gt20words,:]\n",
    "M_indus = tx_indus.shape[1]\n",
    "\n",
    "indus_labels = indus.columns[indus.values.sum(0) > 9]\n",
    "\n",
    "allnames = binfeats.index.values[gt20words]\n",
    "\n",
    "x_sizes = {\"text\": V, \n",
    "           \"bin\": M_b, \n",
    "           \"cat1\": M_c1, \n",
    "           \"cat2\": M_c2, \n",
    "           \"cat3\": M_c3, \n",
    "           \"cat4\": M_c4, \n",
    "           \"cat5\": M_c5, \n",
    "           \"bp\": M_bp, \n",
    "           \"indus\": M_indus, \n",
    "           \"logo\": M_b + 5, \n",
    "           \"all\": V + M_b + 5 + M_bp + M_indus}\n",
    "\n",
    "task_sizes = {\"full\": x_sizes[\"all\"], \n",
    "              \"logo\": x_sizes[\"bin\"] + 5, \n",
    "              \"design\": x_sizes[\"text\"] + x_sizes[\"bp\"] + x_sizes[\"indus\"], \n",
    "              \"mgr\": x_sizes[\"all\"] - x_sizes[\"bp\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Instantiate Model and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "givens = pd.DataFrame(np.concatenate(([[K], list(DECODER_DIMS.values()), [ENCODER_DIMS], [BATCHES], [ITERS], [ADAM_LR], [ANNEALING_BATCHES], [NUM_PARTICLES], [CENTER_BP]]))).T\n",
    "givens.columns = [\"K\", \"text_dec\", \"bin_dec\", \"cat_dec\", \"bp_dec\", \"indus_dec\", \"all_enc\", \"batches\", \"iters\", \"adam_lr\", \"annealing_batches\", \"num_particles\", \"center_bp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create holdout and cross-validation subsets (just the indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FOLDS > 1:\n",
    "    holdout_indices = list(split(np.arange(N), FOLDS))\n",
    "    holdout_indices.append(np.array([]))\n",
    "    fold_indices = [np.setdiff1d(np.arange(N), holdout_indices[i]) for i in range(FOLDS)]\n",
    "    fold_indices.append(np.arange(N))\n",
    "else:\n",
    "    holdout_indices = [np.array([])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the KL annealing schedule (same across each fold):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = np.linspace(MIN_AF, 1., ANNEALING_BATCHES)\n",
    "# schedule = np.concatenate([np.linspace(MIN_AF, 1., round(ANNEALING_BATCHES/4.)) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a516eeef4da491d97f45b1cf86fab6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=2.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32eab6803a6a46289afdbccb04911319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=1000.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iters', style=ProgressStyle(description_width='initial'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cc14a0ef5c422393e4eb4c783acf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iters', style=ProgressStyle(description_width='initial'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8989edc02fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iters\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDISABLE_TQDM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannealing_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mtrack_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannealing_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.7/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# actually perform gradient steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# zero gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.7/site-packages/pyro/optim/optim.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_objs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_objs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check if there's already a save file; if so, augment the save index so the metrics are not overwritten:\n",
    "curfiles = os.listdir()\n",
    "existing_indices = []\n",
    "for file in curfiles:\n",
    "    if(len(file.split(\"_\")) > 1):\n",
    "        if(file.split(\"_\")[-1] == 'metrics.csv'):\n",
    "            existing_indices.append(int(file.split(\"_\")[0]))\n",
    "            \n",
    "if len(existing_indices) > 0:\n",
    "    save_index = max(existing_indices) + 1\n",
    "else:\n",
    "    save_index = 0\n",
    "\n",
    "\n",
    "# Run the model across all folds (sequentially):\n",
    "for fold in tqdm(range(FOLDS+1), desc=\"Folds\", disable=DISABLE_TQDM):\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    \n",
    "    data = SplitData(tx_text, tx_b, tx_c1, tx_c2, tx_c3, tx_c4, tx_c5, tx_bp, tx_indus, \n",
    "                     allnames, test_indices = holdout_indices[fold])   \n",
    "\n",
    "    lmvae = LogoMVAE(K, ENCODER_DIMS, DECODER_DIMS, x_sizes, task_sizes, use_cuda=True)\n",
    "    optimizer = Adam({\"lr\": ADAM_LR})\n",
    "    svi = SVI(lmvae.model, lmvae.guide, optimizer, loss=Trace_ELBO(num_particles = NUM_PARTICLES))\n",
    "    \n",
    "    track_loss = []\n",
    "    for i in tqdm(range(BATCHES), desc=\"Batches\", leave=False, disable=DISABLE_TQDM):\n",
    "\n",
    "        if i < ANNEALING_BATCHES:\n",
    "            annealing_factor = schedule[i]\n",
    "        else:\n",
    "            annealing_factor = 1.\n",
    "\n",
    "        data.training.shuffle()\n",
    "\n",
    "        for j in tqdm(range(ITERS), desc=\"Iters\", leave=False, disable=DISABLE_TQDM):\n",
    "            svi.step(data.training, annealing_factor)\n",
    "            track_loss.append(svi.evaluate_loss(data.training, annealing_factor))\n",
    "    \n",
    "    lmvae.eval()\n",
    "    \n",
    "    lmvae.predict(data.training)\n",
    "    lmvae.pred.metrics.summarize(path = str(save_index) + \"_training_metrics.csv\", index = fold, givens = givens)\n",
    "    lmvae.pred.metrics.save_features_table(path = str(save_index) + \"_training_bin_features.csv\", names = binfeats.columns, index = fold, givens = givens)\n",
    "    lmvae.pred.ll.summarize(path = str(save_index) + \"_training_ll.csv\", index = fold, givens = givens)\n",
    "        \n",
    "    if hasattr(data, 'test'):\n",
    "        data.test.make_torch()\n",
    "        lmvae.predict(data.test)\n",
    "        lmvae.pred.metrics.summarize(path = str(save_index) + \"_test_metrics.csv\", index = fold, givens = givens)\n",
    "        lmvae.pred.metrics.save_features_table(path = str(save_index) + \"_test_bin_features.csv\", names = binfeats.columns, index = fold, givens = givens)\n",
    "        lmvae.pred.ll.summarize(path = str(save_index) + \"_test_ll.csv\", index = fold, givens = givens)\n",
    "        \n",
    "        lmvae.predict(data.test, network = \"logo\")\n",
    "        lmvae.pred.metrics.summarize(path = str(save_index) + \"_logo_metrics.csv\", index = fold, givens = givens)\n",
    "        lmvae.pred.ll.summarize(path = str(save_index) + \"_logo_ll.csv\", index = fold, givens = givens)\n",
    "                \n",
    "        lmvae.predict(data.test, network = \"des\")\n",
    "        lmvae.pred.metrics.summarize(path = str(save_index) + \"_des_metrics.csv\", index = fold, givens = givens)\n",
    "        lmvae.pred.metrics.save_features_table(path = str(save_index) + \"_des_bin_features.csv\", names = binfeats.columns, index = fold, givens = givens)\n",
    "        lmvae.pred.ll.summarize(path = str(save_index) + \"_des_ll.csv\", index = fold, givens = givens)\n",
    "                \n",
    "        lmvae.predict(data.test, network = \"mgr\")\n",
    "        lmvae.pred.metrics.summarize(path = str(save_index) + \"_mgr_metrics.csv\", index = fold, givens = givens)\n",
    "        lmvae.pred.ll.summarize(path = str(save_index) + \"_mgr_ll.csv\", index = fold, givens = givens)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct and save z-space neighbors table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lmvae.predict(data.training)\n",
    "\n",
    "z = lmvae.pred.z.z_loc.cpu().numpy()\n",
    "end_names = data.training.names\n",
    "# z_est = z_est[:,z_est.std(0) > 0.5]\n",
    "\n",
    "dist_z = compute_distance(z)\n",
    "\n",
    "test_firms = ['itw','harman-intl','lilly','goldman-sachs','21st-century-fox','facebook','gucci','old-navy','3m','actavis','mcdonalds', 'kfc']\n",
    "test_neighbors = [end_names[dist_z[np.where(end_names == test_firms[i])[0][0],:].argsort()][1:5] for i in range(len(test_firms))]\n",
    "test_dist = [np.sort(dist_z[np.where(end_names == test_firms[i])[0][0],:].round(2))[1:5] for i in range(len(test_firms))]\n",
    "formatted_neighbors = [\", \".join(test_neighbors[i].tolist()) for i in range(len(test_neighbors))]\n",
    "\n",
    "neighbors_df = pd.DataFrame(test_neighbors)\n",
    "neighbors_df.index = test_firms\n",
    "neighbors_df.columns = np.arange(1,5)\n",
    "\n",
    "if not givens.empty:\n",
    "    for col in givens.columns:\n",
    "                neighbors_df[col] = givens[col].values[0]\n",
    "\n",
    "neighbors_df.to_csv(str(save_index) + \"_neighbors_table.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro",
   "language": "python",
   "name": "pyro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
